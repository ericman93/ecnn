{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution1D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pokemon import *\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "get_cards(X, y)\n",
    "\n",
    "sample = 5\n",
    "y = np.atleast_2d(keras.utils.to_categorical(y)[sample])\n",
    "X = np.atleast_2d(X[sample].reshape(X[sample].size))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=X.size, activation='softmax', use_bias=True, kernel_initializer=keras.initializers.Ones()))\n",
    "sgd = keras.optimizers.SGD(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "0s - loss: 1.0986\n",
      "Epoch 2/10\n",
      "0s - loss: 0.9561\n",
      "Epoch 3/10\n",
      "0s - loss: 0.8355\n",
      "Epoch 4/10\n",
      "0s - loss: 0.7344\n",
      "Epoch 5/10\n",
      "0s - loss: 0.6485\n",
      "Epoch 6/10\n",
      "0s - loss: 0.5770\n",
      "Epoch 7/10\n",
      "0s - loss: 0.5148\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4640\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4203\n",
      "Epoch 10/10\n",
      "0s - loss: 0.3820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b580adac8>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5400)\n"
     ]
    }
   ],
   "source": [
    "inputs = [-27.70588483 ,-32.96674124,   6.87672843]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.57108479e-16   4.96823163e-18   1.00000000e+00]\n",
      "34.5826\n",
      "[ -1.00000000e+00   4.96823163e-18   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-7\n",
    "with tf.Session() as s:    \n",
    "    feed = {X : X}\n",
    "    p = tf.nn.softmax(logits)\n",
    "    t = np.array([1,0,0])\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=t)\n",
    "    print(s.run(p, feed_dict=feed))\n",
    "    print(s.run(loss, feed_dict=feed))\n",
    "    print(s.run(tf.gradients(loss, [logits])[0], feed_dict=feed))\n",
    "\n",
    "\n",
    "    \n",
    "#     logits = tf.Variable([1/3, 1/3, 1/3])\n",
    "#     y = tf.constant([1,0,0], dtype=tf.float32)\n",
    "\n",
    "# #     loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)    \n",
    "    \n",
    "#     output = tf.nn.softmax(logits)\n",
    "#     print(s.run(tf.nn.softmax([3684.99286736 , 2975.72622257 , 2975.72622257])))\n",
    "#     print(s.run(tf.gradients(p, [logits]) , feed_dict=feed))\n",
    "    \n",
    "    #print(s.run(loss, feed_dict=feed))\n",
    "    #print(s.run(tf.gradients(loss, [logits])[0], feed_dict=feed))\n",
    "    \n",
    "    #print(s.run(tf.clip_by_value(p, epsilon, 1- epsilon)))\n",
    "#     print(s.run(tf.nn.softmax_cross_entropy_with_logits(logits=p,labels=t)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.99373946e-01,   6.26053455e-04,   7.72659646e-11])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cnn.steps.activation import Softmax\n",
    "\n",
    "Softmax.forward_propagation(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
