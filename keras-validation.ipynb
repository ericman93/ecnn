{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution1D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting cards\n",
      "trainer\n",
      "pokemon\n",
      "energy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pokemon import *\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "get_cards(X, y)\n",
    "# X = np.array([[\n",
    "#     [\n",
    "#         [1, 2, 3, 4, 5, 6],\n",
    "#         [1, 2, 3, 4, 5, 6],\n",
    "#         [1, 2, 3, 4, 5, 6],\n",
    "#         [1, 2, 3, 4, 5, 6]\n",
    "#     ]\n",
    "# ]])\n",
    "# y = [[0,1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "0s - loss: 1.0986\n",
      "Epoch 2/2\n",
      "0s - loss: 0.3899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04dcdbbf60>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 4\n",
    "# y = np.atleast_2d(y)\n",
    "ny = np.atleast_2d(keras.utils.to_categorical(y)[sample])\n",
    "nX = np.atleast_2d(X[sample].reshape(X[sample].size))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, \n",
    "                input_dim=nX.size, \n",
    "                activation='softmax', \n",
    "                use_bias=True, \n",
    "                kernel_initializer=keras.initializers.Ones()))\n",
    "sgd = keras.optimizers.SGD(lr=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "model.fit(nX, ny, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9609375   0.96484375  0.97265625 ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "inputs = [-27.70588483 ,-32.96674124,   6.87672843]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.57108479e-16   4.96823163e-18   1.00000000e+00]\n",
      "34.5826\n",
      "[ -1.00000000e+00   4.96823163e-18   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-7\n",
    "with tf.Session() as s:    \n",
    "    X = tf.Variable([  1.93437912e-07  , 9.81437858e-01 ,  1.85619488e-02])\n",
    "    feed = {logits : inputs}\n",
    "    p = tf.nn.softmax(logits)\n",
    "    t = np.array([1,0,0])\n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=t)\n",
    "    print(s.run(p, feed_dict=feed))\n",
    "    print(s.run(loss, feed_dict=feed))\n",
    "    print(s.run(tf.gradients(loss, [logits])[0], feed_dict=feed))\n",
    "\n",
    "\n",
    "    \n",
    "#     logits = tf.Variable([1/3, 1/3, 1/3])\n",
    "#     y = tf.constant([1,0,0], dtype=tf.float32)\n",
    "\n",
    "# #     loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)    \n",
    "    \n",
    "#     output = tf.nn.softmax(logits)\n",
    "#     print(s.run(tf.nn.softmax([3684.99286736 , 2975.72622257 , 2975.72622257])))\n",
    "#     print(s.run(tf.gradients(p, [logits]) , feed_dict=feed))\n",
    "    \n",
    "    #print(s.run(loss, feed_dict=feed))\n",
    "    #print(s.run(tf.gradients(loss, [logits])[0], feed_dict=feed))\n",
    "    \n",
    "    #print(s.run(tf.clip_by_value(p, epsilon, 1- epsilon)))\n",
    "#     print(s.run(tf.nn.softmax_cross_entropy_with_logits(logits=p,labels=t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cceef877ab72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#         self.updates = [K.update_add(self.iterations, 1)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "feed = {logits : inputs}\n",
    "loss = \n",
    "sgd = SGD()\n",
    "grads = sgd.get_gradients(loss, params)\n",
    "#         self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "#         lr = self.lr\n",
    "#         if self.initial_decay > 0:\n",
    "#             lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "#                                                   K.dtype(self.decay))))\n",
    "#         # momentum\n",
    "#         shapes = [K.int_shape(p) for p in params]\n",
    "#         moments = [K.zeros(shape) for shape in shapes]\n",
    "#         self.weights = [self.iterations] + moments\n",
    "#         for p, g, m in zip(params, grads, moments):\n",
    "#             v = self.momentum * m - lr * g  # velocity\n",
    "#             self.updates.append(K.update(m, v))\n",
    "\n",
    "#             if self.nesterov:\n",
    "#                 new_p = p + self.momentum * v - lr * g\n",
    "#             else:\n",
    "#                 new_p = p + v\n",
    "\n",
    "#             # Apply constraints.\n",
    "#             if getattr(p, 'constraint', None) is not None:\n",
    "#                 new_p = p.constraint(new_p)\n",
    "\n",
    "#             self.updates.append(K.update(p, new_p))\n",
    "#         return self.updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
